{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f8e927-6dd7-4a8c-93cb-71a134fbd0d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# An introduction to statistical distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0691b974-dca2-4d0d-8169-5c9f04b2dd1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import modules\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52455a5f-2980-48fa-989b-cf36d2181d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "\n",
    "plt.style.use('custom.mplstyle')\n",
    "COLORS = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d022a6-9481-44dc-9b44-401edde71dc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ideas covered\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70402454-7366-4bbf-9c71-0516b4a90e53",
   "metadata": {},
   "source": [
    "We seek to understand probability distributions which characterize fundamental processes in statistics (and physics) and can be used as (baseline) models for real-world phenomena. We will look at the following distributions:\n",
    "\n",
    "- [Binomial](https://en.wikipedia.org/wiki/Binomial_distribution)\n",
    "- [Normal/Gaussian](https://en.wikipedia.org/wiki/Normal_distribution)\n",
    "\n",
    "The hyperlinks will direct you to the Wikipedia pages for each distribution. These mathematical Wikipedia pages typically contain a wealth of information. They are useful for developing your intuition for these distributions and are references for neat properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae04ccf-2834-4823-8865-e4fd65ecfa95",
   "metadata": {},
   "source": [
    "# Random number generators\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa464a5-a492-4a68-ac70-ef80ef5f4b85",
   "metadata": {},
   "source": [
    "To study statistical distributions, we need a way of generating randomness. One way computers can generate randomness is by using a [pseudorandom number generator](https://en.wikipedia.org/wiki/Pseudorandom_number_generator). The nitty-gritty details of this topic aren't necessary to work through this notebook. However, a few things should be understood here:\n",
    "\n",
    "- **Psuedorandom numbers aren't actually random!**\n",
    "- Sequences of pseudorandom numbers are determined by a *seed*. This seed enables *reproducibility*.\n",
    "\n",
    "We initialize a pseudorandom number generation (```rng```) with ```seed=0``` in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5e077-7e48-4bb6-b4ff-357b034fdf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068cc32-16b2-4f62-8a6b-cda6a032366a",
   "metadata": {},
   "source": [
    "Calling `rng.random()` produces a random number $\\in [0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89db48d-2c4b-4358-bf46-95b702e56e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5d682-7811-40ff-b59f-c269e0d0eae6",
   "metadata": {},
   "source": [
    "To see how this random number generator is reproducible, generate three random numbers, recreate a `default_rng` object with the same seed, generate three random numbers again. Then generate three more random numbers to see the sequence continued. Change the seed and observe the same sequence of numbers is always produced when random number generators have the same seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e6b88-99d1-4439-940c-bc488bcf80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "print('Initialized first random number generator.')\n",
    "for i in range(3):\n",
    "    print(rng.random())\n",
    "    \n",
    "print('\\nInitialized second random number generator with same seed.')\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "for i in range(3):\n",
    "    print(rng.random())\n",
    "    \n",
    "print('\\nWithout reinitializing, rng will continue generating random numbers according to its sequence.')\n",
    "for i in range(3):\n",
    "    print(rng.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821aa1c0-2870-4bd9-83cf-09135e174bce",
   "metadata": {},
   "source": [
    "The point here is don't keep initializing your `rng`! Set it once, and use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f9362-f6a5-4a9c-9cf1-67f995baa234",
   "metadata": {},
   "source": [
    "### An important note on function parameters\n",
    "\n",
    "When we initialized numpy arrays, we used a parameter called `shape` to specify the size of the dimensions. E.g.,\n",
    "\n",
    "```python\n",
    "np.zeros(shape=10)\n",
    "np.ones(shape=(4, 50, 25))\n",
    "```\n",
    "\n",
    "When generating random numbers using `rng`, we can generate many random numbers at once. In fact, it is recommended and much more efficient to generate all the random numbers you will need rather than generating them one at a time. However, instead of using the `shape` parameter, we use the `size` parameter. (You can check various numpy docs.) This `size` parameter is used across all numpy functions for random number generation.\n",
    "\n",
    "Try generating 10 random numbers using `shape` and then try using `size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f61eb-c315-45e5-8e2d-fafd4128bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.random(shape=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a9ec5-d73a-4075-aa12-32fb029c9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.random(size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bd9b0-2de0-4109-b6a1-b16eb062416a",
   "metadata": {},
   "source": [
    "We can generate random numbers in a multidimensional way easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b4b70-5a34-4d14-b098-5e7b84a1413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.random(size=(3, 4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d43473-d769-479e-afbb-ab4600483cff",
   "metadata": {},
   "source": [
    "# The binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721209ef-1a5f-48ed-802b-303f040b3063",
   "metadata": {},
   "source": [
    "A binomial random variable is a sum of Bernoulli random variables. Let $B$ be a Bernoulli random variable and $B'$ be a binomial random variable. Then for a binomial process with $n$ trials, we have\n",
    "\n",
    "$$\n",
    "B' = \\sum_{i=1}^{n} B_i\n",
    "$$\n",
    "\n",
    "As a reminder, for a Binomial process with parameters $n$, the number of Bernoulli trials (coin flips), and $p$, the probability of a seeing a heads, the probability of observing $k \\in \\{0, 1, 2, 3, \\ldots, n \\}$ heads is\n",
    "\n",
    "$$\n",
    "P(k | p, n) = {n \\choose k} p^k (1-p)^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b190-b292-4d99-8313-553dd798243c",
   "metadata": {},
   "source": [
    "## Numpy interlude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffde7d2-0961-46be-a810-6fbc771ae756",
   "metadata": {},
   "source": [
    "As stated above, we can simulate many random numbers at the same time. Let's exploit that functionality. Hopefully, the ensuing code will be more intutive.\n",
    "\n",
    "Let's simulate $R$ binomial processes which each have $n$ Bernoulli trials (coin flips). We can do so by generating an $R \\times n$ matrix of random numbers.\n",
    "\n",
    "|                    | Bernoulli trial 1 | Bernoulli trial 2 | Bernoulli trial 3 | ... |  Bernoulli trial $n$ |\n",
    "| -----------        | -----------       |    ----------     | -----------       | ----------- | ------|\n",
    "| Binom process 1    | 0.252             | 0.842             | 0.928             | ...      | 0.125  |\n",
    "| Binom process 2    | 0.484             | 0.238             | 0.101             | ...      | 0.589  |\n",
    "| Binom process 3    | 0.661             | 0.747             | 0.747             | ...      | 0.324  |\n",
    "| ...                | ...               | ...               | ...               | ...      | ...    |\n",
    "| Binom process $R$  | 0.313             | 0.933             | 0.027             | ...      | 0.481  |\n",
    "\n",
    "Then we can check which random numbers correspond to heads or tails. Random numbers which are successes are those with value $\\leq p$. For simplicity, let's take $p=0.5$\n",
    "\n",
    "|                    | Bernoulli trial 1 | Bernoulli trial 2 | Bernoulli trial 3 | ... |  Bernoulli trial $n$ |\n",
    "| -----------        | -----------       |    ----------     | -----------       | ----------- | ------|\n",
    "| Binom process 1    | H                 | T                 | T                 | ...      | H  |\n",
    "| Binom process 2    | H                 | H                 | T                 | ...      | T  |\n",
    "| Binom process 3    | T                 | T                 | T                 | ...      | H  |\n",
    "| ...                | ...               | ...               | ...               | ...      | ...    |\n",
    "| Binom process $R$  | H                 | T                 | H                 | ...      | H  |\n",
    "\n",
    "Programmatically, we can implement this using bools (whether something is True or False). Let's rephrase our coin flip experiment from, \"Heads or tails?\" to, \"Is the outcome a heads?\" Then we can change our label from heads or tails to True (we observed a heads) or False (we observed a tails). T = True and F = False in the following table.\n",
    "\n",
    "|                    | Bernoulli trial 1 | Bernoulli trial 2 | Bernoulli trial 3 | ... |  Bernoulli trial $n$ |\n",
    "| -----------        | -----------       |    ----------     | -----------       | ----------- | ------|\n",
    "| Binom process 1    | T                 | F                 | F                 | ...      | T  |\n",
    "| Binom process 2    | T                 | T                 | F                 | ...      | F  |\n",
    "| Binom process 3    | F                 | F                 | F                 | ...      | T  |\n",
    "| ...                | ...               | ...               | ...               | ...      | ...    |\n",
    "| Binom process $R$  | T                 | F                 | T                 | ...      | T  |\n",
    "\n",
    "Next, we need to count how many heads we have for each binomial processes. We count each how many Trues are in each row and get our value. For simplicity, let's assume $n=4$ and take the values from above.\n",
    "\n",
    "|                    | $k$ | \n",
    "| -----------        | -----------       | \n",
    "| Binom process 1    | 2                 |\n",
    "| Binom process 2    | 2                 |\n",
    "| Binom process 3    | 1                 | \n",
    "| ...                | ...               |\n",
    "| Binom process $R$  | 3                 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4913f507-5c31-4d29-9cc9-c7681811f1d2",
   "metadata": {},
   "source": [
    "### Write a function to simulate a binomial process.\n",
    "\n",
    "It should have four parameters\n",
    "- `rng`, the random number generator\n",
    "- `p`, the probability of a success\n",
    "- `num_trials`, the number of Bernoulli trials for each binomial process\n",
    "- `num_realizations`, the amount of binomial processes/experiments to simulate\n",
    "\n",
    "It should return\n",
    "- `outcomes`, a numpy array containing how many successes were in each binomial process\n",
    "- `distribution`, a numpy array containing the binomial probabilities\n",
    "\n",
    "We use [`np.sum`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) which sums numpy arrays along whichever dimension we specify and [`np.bincount`](https://numpy.org/doc/stable/reference/generated/numpy.bincount.html) which counts the number of occurrences for each non-negative integer. We also use [`np.trim_zeros`](https://numpy.org/doc/stable/reference/generated/numpy.trim_zeros.html) to clean things up a bit.\n",
    "\n",
    "Let's build up the function before we write it. Let's simulate 4 binomial processes (experiments) with $p=0.5$ and $n=6$, so a fair coin and 6 coin flips per experiment. We begin by making a matrix of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8f303-3661-4d12-8e67-049d14ac892b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5240c91a-bdc0-4577-ad51-7331b79e3781",
   "metadata": {},
   "source": [
    "We convert these probabilities into heads (True, we did see a head) and tails (False, we did not see a head)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9cccc4-ad66-4902-8805-edf1844269f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "463663db-114b-4372-b47f-6fcdeb502031",
   "metadata": {},
   "source": [
    "True and False are booleans. This means that True = 1 and False = 0. (They are binary values.) We can exploit this behavior. Because a binomial process is the sum of how many heads we see, we sum all the columns for each row. We use `np.sum` and the keyword `axis=1` to tell it to sum over all the columns for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274f16b-2a61-4727-8da4-a8af12c12927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b049f5d-10e8-4fc6-904a-79aa84ae3841",
   "metadata": {},
   "source": [
    "Does this match how many Trues are in each row?\n",
    "\n",
    "This gives us our Binomial random numbers. We could be done here. But let's also calculate the probabilities (frequenicies) of each number in our array. We'll use this later.\n",
    "\n",
    "Simulating a Binomial process gives us an non-negative integer, how many heads we observed after some coin flips. We use `np.bincount` which counts the number of occurrences for each non-negative integer in an array. I.e., the number in the 0th position is how many 0s there were in the array, the number in the 1st position is how many 1s there were in the array, the number in the 2nd position is how many 2s there were in the array, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62f40f-f64a-4f56-a978-a535c3be9276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14c755be-8c4c-459b-867d-6383bc2b6495",
   "metadata": {},
   "source": [
    "We have the number of occurrences, but we'd like to convert these number of occurrences to probabilities/frequencies. We need to divide these numbers by how many experiments we performed in total. We could divide by $n$ or use `binom_rands.shape[0]` which also tells us how many experiments performed. (`binom_rands.shape[0]` gives how many numbers are in the array `binom_rands`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7fb0b-428b-46b6-ab93-f12620a8a1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a4ecba8-35a1-416c-a95f-9d62765f82a3",
   "metadata": {},
   "source": [
    "Finally, because of how we're going to write the functions below, let's get of the trailing 0s at either end of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d5d40-7bbc-46aa-a4ec-5b5a99ec7aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5f6250b-222a-41a4-a976-e217a01bc6a3",
   "metadata": {},
   "source": [
    "Now, let's construct a function using the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23450c-3815-4b8b-bbc8-8399b148c670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_binomial(rng, p, num_trials, num_realizations):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab38faa-40c7-4427-9dcf-f2e0cd1b4c20",
   "metadata": {},
   "source": [
    "Let's see what this returns for $p=0.3$, `num_trials` $= 5$, `num_realizations`$=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2f40b-a910-460b-a9cb-4ea74e90ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binomial(rng, 0.3, 5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e4a8e-66eb-4738-96d4-db33b184b9fb",
   "metadata": {},
   "source": [
    "Let's see what this returns for $p=0.3$, `num_trials` $= 100$, `num_realizations`$=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2963a75-2c7c-41a3-8185-66bf252e5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binomial(rng, 0.3, 100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b082d9-b13c-4401-8b5d-fccdc9f41ab2",
   "metadata": {},
   "source": [
    "### Run your function using $p=0.3$, `num_trials`$=5$, `num_realizations` $\\in \\{10, 10^2, 10^3, 10^4, 10^5, 10^6\\}$. Create a figure with a 2 x 3 grid of axes objects. Each axes object should correspond to a given number of realizations.\n",
    "\n",
    "Initialize `fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))`.\n",
    "\n",
    "On each axes object:\n",
    "- Plot a histogram of the outcomes. Use bins which are centered around integers and `density=True`. Hint: think about how many bins you need and what bins define. Label this as \"simulation.\"\n",
    "- Use a lineplot and plot the true values of the distribution using `sp.binom.pmf` vs. the number of successes. Set `color='black'` and `linewidth=1`. Label this as \"theory.\"\n",
    "- Label the y-axis \"PMF\" and the x-axis \"# successes\"\n",
    "- Give each axes object a title corresponding to the number of realizations being plotted.\n",
    "- Tip: an easy way to make a 2-dimensional numpy array into a 1-dimensional numpy array is by using [`np.ravel`](https://numpy.org/doc/stable/reference/generated/numpy.ravel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d181a-1dbd-4c96-ba6f-3a3ab48f946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_realizations_arr = 10**np.arange(1, 7)\n",
    "n = 5\n",
    "p = 0.3\n",
    "\n",
    "results = []\n",
    "for num_realizations in num_realizations_arr:\n",
    "    results.append(my_binomial(rng, p, n, num_realizations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e42bc-b977-4f13-8c75-682c4aca4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "\n",
    "for result, ax in zip(results, np.ravel(axes)):\n",
    "    outcomes = result[0]\n",
    "    distribution = result[1]\n",
    "    bins_centered = np.arange(np.min(outcomes), np.max(outcomes) + 2) - 0.5\n",
    "    bins = bins_centered[:-1] + 0.5\n",
    "    \n",
    "    ax.hist(outcomes, bins=bins_centered, density=True, rwidth=0.9, label='simulation')\n",
    "    ax.plot(bins, sp.binom.pmf(bins, n, p), color='black', linewidth=1, label='theory')\n",
    "    ax.set_ylabel('PMF')\n",
    "    ax.set_xlabel('# successes')\n",
    "    ax.set_title('# realizations: ' + str(outcomes.shape[0]))\n",
    "    ax.legend()\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e96574-fc97-410d-9dbf-0be6bd87d12e",
   "metadata": {},
   "source": [
    "# Statistical quantities (statistic)\n",
    "___\n",
    "\n",
    "A statistic is a quantity which is calculated over a set of numbers, such as a sample or distribution. Because statistics are computed using a function which takes in a bunch of numbers and spits out a single (or a few) number(s), we can think of these quantities as *summarizing* something about the data.\n",
    "\n",
    "## Mean\n",
    "\n",
    "One of the first statistical quantities that comes to mind is the **mean**. The mean answers the question of what is the average value in the sample/distribution?\n",
    "\n",
    "Given a sample $X$ of size $N$, we can calculate the mean using\n",
    "\n",
    "$$\n",
    "\\langle x \\rangle = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$\n",
    "\n",
    "We can also create a function $g(x)$ which counts the multiplicity of the $x$ which are in in $X$. E.g., if $X = \\{1, 1, 3, 3, 4, 7, 7, 7 \\}$, then $g(1) = 2$, $g(3) = 2$, $g(4) = 1$, $g(7) = 3$. Any other values of $x$ are 0 since they do not appear in $X$: e.g., $g(10) = 0$. Instead of summing over each quantity in our sample, we can sum over the unique quantities in our sample and use this counting function to weight the values of $x$ accordingly:\n",
    "\n",
    "$$\n",
    "\\langle x \\rangle = \\frac{1}{N} \\sum_{x \\in X} g(x)\n",
    "$$\n",
    "\n",
    "Moving $N$ inside the sum, we can recognize $g(x) / N$ as the *probability* that $x$ is in $X$ and define $P(x_i) = g(x_i) / N$. Then the mean can be computed knowing the distribution $P(x)$ and knowing what values of $x$ are or can be in $X$ (i.e., the support of $P(x)$).\n",
    "\n",
    "$$\n",
    "\\langle x \\rangle = \\sum_{x \\in X} x P(x)\n",
    "$$\n",
    "\n",
    "For non-discrete $x$, change the sum to an integral with the appropriate measure.\n",
    "\n",
    "$$\n",
    "\\langle x \\rangle = \\int_{-\\infty}^{\\infty} x P(x) dx\n",
    "$$\n",
    "\n",
    "In general, for a distribution $A(x)$ which might not be normalized, $\\int_{-\\infty}^{\\infty} A(x) \\neq 1$,\n",
    "\n",
    "$$\n",
    "\\langle x \\rangle = \\frac{\\int_{-\\infty}^{\\infty} x A(x) dx}{\\int_{-\\infty}^{\\infty} A(x) dx}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54173349-7a41-4ae3-8289-6be66453f909",
   "metadata": {},
   "source": [
    "### Write two functions to calculate the mean: one which sums over the values in the sample and one which uses the probabilities of the quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a6e9d-f843-4de8-b0e9-a5031bf4b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mean(x):\n",
    "    \"\"\"\n",
    "    Use np.sum: https://numpy.org/doc/stable/reference/generated/numpy.sum.html\n",
    "    To get the number of values in a numpy array, use x.shape[0]\n",
    "    Use these two ideas to write your function.\n",
    "    No need for a for loop.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def distribution_mean(x, prob):\n",
    "    \"\"\"\n",
    "    x and prob are numpy arrays. They have a direct correspondence to one another.\n",
    "    I.e., the probability of x[2] is prob[2]\n",
    "    Use np.sum and the direct correspondence to write your function.\n",
    "    Remember that you can perform multiplication on numpy arrays!\n",
    "    E.g., if a = np.array([1, 2, 3]) and b = np.array([4, 5, 6]),\n",
    "    then a * b = np.array(4, 10, 18]).\n",
    "    No need for a for loop.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1b41c-871c-4ff8-b076-ccfb8967e276",
   "metadata": {},
   "source": [
    "### Calculate the mean of the binomial process using $p=0.3$, $n=5$, and `num_realizations` $\\in \\{10, 10^2, 10^3, 10^4, 10^5, 10^6\\}$. Compare your functions to `np.mean` and the analytic solution $np$. How good is the estimate of the mean at using a small number of realizations? How does the mean change as the number of realizations increases? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632ee08-330c-4c55-9156-9ff732d234f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, distribution) in results:\n",
    "    distribution_x = np.arange(np.min(x), np.max(x) + 1)\n",
    "    print('num realizations:', x.shape[0])\n",
    "    print('sample mean:', sample_mean(x))\n",
    "    print('prob mean:', distribution_mean(distribution_x, distribution))\n",
    "    print('numpy mean:', np.mean(x))\n",
    "    print('analytic mean:', n * p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e02e8-db6e-441e-9dc1-4c9f9d5d0450",
   "metadata": {},
   "source": [
    "From now on, use `np.mean` when computing sample means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea23408-77e0-4ee0-abfa-d86b1e646d63",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "The variance is another statistic. It tells us about the spread of a set of numbers in relation to the set's mean. The variance is the expected squared deviation from the mean of a set $X$. Mathematically, it is\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathrm{var}(x) &= \\langle \\left(x - \\langle x \\rangle \\right)^2 \\rangle \\\\\n",
    "&= \\langle x^2 - 2 x \\langle x \\rangle + \\langle x \\rangle^2 \\rangle \\\\\n",
    "&= \\langle x^2 \\rangle - 2 \\langle x \\rangle^2 + \\langle x \\rangle^2 \\\\\n",
    "&= \\langle x^2 \\rangle - \\langle x \\rangle^2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Summing over quanities in a sample, we have\n",
    "\n",
    "$$\n",
    "\\mathrm{var}(x) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( x_i - \\langle x \\rangle \\right)^2\n",
    "$$\n",
    "\n",
    "Using probability distributions, we have\n",
    "\n",
    "$$\n",
    "\\mathrm{var}(x) = \\int x^2 P(x) dx - \\left(\\int x P(x) dx \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a8350-f80c-469e-a665-f0189570fa4d",
   "metadata": {},
   "source": [
    "### Write two functions to calculate the variance: one which sums over the values in the sample and one which uses the probabilities of the quantities. Each function should utilize the respective function to calculate the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f1e67-47e0-43cb-b308-b6de95f9c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_var(x):\n",
    "    \"\"\"\n",
    "    Use your sample_mean function to get your mean.\n",
    "    Again, use x.shape[0] to get the amount of values in the numpy array.\n",
    "    Use np.sum to compute the sum.\n",
    "    No need for any for loops.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def distribution_var(x, prob):\n",
    "    \"\"\"\n",
    "    Use your distribution_var function to get your mean.\n",
    "    Use np.sum and the direct correspondence between x and prob.\n",
    "    Remember numpy arrays can be squared as you would expect them to be!\n",
    "    If a = np.array([2, 5, 7]), then a**2 = np.array([4, 25, 49]).\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713e2e3-f422-4d20-a877-9cec5870a4b9",
   "metadata": {},
   "source": [
    "### Calculate the variance of the binomial process using $p=0.3$, $n=5$, and `num_realizations` $\\in \\{10, 10^2, 10^3, 10^4, 10^5, 10^6\\}$. Compare your functions to `np.var` and the analytic solution $np(1-p)$. How good is the estimate of the variance using a small number of realizations? How does the variance change as the number of realizations increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d0711-5913-4c2c-9aa4-20930267f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, distribution) in results:\n",
    "    distribution_x = np.arange(np.min(x), np.max(x) + 1)\n",
    "    print('num realizations:', x.shape[0])\n",
    "    print('sample var:', sample_var(x))\n",
    "    print('prob var:', distribution_var(distribution_x, distribution))\n",
    "    print('numpy var:', np.var(x))\n",
    "    print('analytic var', n * p * (1 - p))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce1234-c85b-4f00-accc-3e6d3c363fc0",
   "metadata": {},
   "source": [
    "### Repeat the above using `num_trials`$=100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a3747-1264-42de-9cb5-27d9655dd417",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_realizations_arr = 10**np.arange(1, 7)\n",
    "n = 100\n",
    "p = 0.3\n",
    "\n",
    "results = []\n",
    "for num_realizations in num_realizations_arr:\n",
    "    results.append(my_binomial(rng, p, n, num_realizations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88381b-8040-4e1a-a710-0c133c1d7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "for result, ax in zip(results, axes.ravel()):\n",
    "    outcomes = result[0]\n",
    "    distribution = result[1]\n",
    "    bins_centered = np.arange(np.min(outcomes), np.max(outcomes) + 2) - 0.5\n",
    "    bins = bins_centered[:-1] + 0.5\n",
    "    \n",
    "    ax.hist(outcomes, bins=bins_centered, density=True, rwidth=0.9, label='simulation')\n",
    "    ax.plot(bins, sp.binom.pmf(bins, n, p), color='black', linewidth=1, label='theory')\n",
    "    ax.set_ylabel('PMF')\n",
    "    ax.set_xlabel('# successes')\n",
    "    ax.set_title('# realizations: ' + str(outcomes.shape[0]))\n",
    "    ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40693edd-cc45-4cdf-a8c3-ed73dcc8d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, distribution) in results:\n",
    "    distribution_x = np.arange(np.min(x), np.max(x) + 1)\n",
    "    print('num realizations:', x.shape[0])\n",
    "    print('sample mean:', sample_mean(x))\n",
    "    print('prob mean:', distribution_mean(distribution_x, distribution))\n",
    "    print('numpy mean:', np.mean(x))\n",
    "    print('analytic mean:', n * p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26d412-025d-4cd4-9b20-91d105a3da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, distribution) in results:\n",
    "    distribution_x = np.arange(np.min(x), np.max(x) + 1)\n",
    "    print('num realizations:', x.shape[0])\n",
    "    print('sample var:', sample_var(x))\n",
    "    print('prob var:', distribution_var(distribution_x, distribution))\n",
    "    print('numpy var:', np.var(x))\n",
    "    print('analytic var', n * p * (1 - p))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222c43c-10b6-464f-bcd0-bd6abb2de706",
   "metadata": {},
   "source": [
    "# Normal/Gaussian distribution\n",
    "___\n",
    "\n",
    "The normal/Gaussian distribution arises in a multitude of ways. One of these ways is through the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem). The central theorem essentially states that, under certain conditions, the distribution of independent and identically distributed random variables summed together tends toward a normal distribution. For instance, simulating binomial processes with $n=100$ above, we see this bell-curve/normal behavior. Notably, a normal distribution can only **approximate** binomial processes with large $N$.\n",
    "\n",
    "There normal distribution is parameterized by its mean $\\mu$ and variance $\\sigma^2$. For normally distributed $x$, its probability density is given by\n",
    "\n",
    "$$\n",
    "    P(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( \\frac{-1}{2} \\left( \\frac{x - \\mu}{\\sigma} \\right)^2 \\right)\n",
    "$$\n",
    "\n",
    "To fit a normal distribution to data, we only need the mean and variance of the data. In practice, the normal distribution is coded up using its mean and its standard deviation (the square root of its variance), so that's the parameterization we use below for the scipy functions.\n",
    "\n",
    "## When does a Gaussian distribution approximate a binomial distribution well?\n",
    "\n",
    "### Let's get a feeling for how many Bernoulli trials we need to sum together for a binomial process to be approximately normal. Let $p=0.3$ and `num_realizations`=$10000$. Try out $n \\in \\{2, 5, 10, 20, 50, 100\\}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5d53b-42fc-49c4-a4b9-d590848ad16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials_arr = np.array([2, 5, 10, 20, 50, 100])\n",
    "p = 0.3\n",
    "num_realizations = 10000\n",
    "binomial_rands = []\n",
    "for num_trials in num_trials_arr:\n",
    "    binomial_rands.append(my_binomial(rng, p, num_trials, num_realizations)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c79d5e-b08d-4494-9780-c411a96081dd",
   "metadata": {},
   "source": [
    "### Create a figure with a 2 x 3 grid of axes objects. Each axes object should correspond to a given number of trials for a binomial process. Plot a histogram of the binomial random variables using bins centered correctly. Fit a normal distribution using the mean and standard deviation of the binomial random variables and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3e814-e8f0-4c7a-b465-9fbe44b6f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "for ax, rands, num_trials in zip(np.ravel(axes), binomial_rands, num_trials_arr):\n",
    "    bins_centered = np.arange(np.min(rands), np.max(rands) + 2) - 0.5\n",
    "    bins = bins_centered[:-1] + 0.5\n",
    "    ax.hist(rands, bins=bins_centered, density=True, rwidth=0.9, label='binomial')\n",
    "    ax.plot(bins, sp.norm.pdf(bins, np.mean(rands), np.std(rands)), linewidth=2, label='Gaussian fit')\n",
    "    ax.set_title('$n$ = ' + str(num_trials))\n",
    "    ax.set_ylabel('PMF')\n",
    "    ax.set_xlabel('# successes')\n",
    "    ax.legend()\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d28e0a-ad53-4b24-89c3-aaeacbc638d3",
   "metadata": {},
   "source": [
    "### Repeat the same plots as above but instead use a logarithmic scale on the y-axis. Inspecting the tails of distributions is incredibly important for letting you know if your fit is good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b7f1c-24ef-4f07-a2b1-b78b486f89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "for ax, rands, num_trials in zip(np.ravel(axes), binomial_rands, num_trials_arr):\n",
    "    bins_centered = np.arange(np.min(rands), np.max(rands) + 2) - 0.5\n",
    "    bins = bins_centered[:-1] + 0.5\n",
    "    ax.hist(rands, bins=bins_centered, density=True, rwidth=0.9, label='binomial')\n",
    "    ax.plot(bins, sp.norm.pdf(bins, np.mean(rands), np.std(rands)), linewidth=2, label='Gaussian fit')\n",
    "    ax.set_title('$n$ = ' + str(num_trials))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('PMF')\n",
    "    ax.set_xlabel('# successes')\n",
    "    ax.legend()\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76facb7-8521-4bc8-95c3-e722b0c049d5",
   "metadata": {},
   "source": [
    "## When does a Gaussian approximate sums of uniform random numbers well?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145e47c-f797-4eb3-821a-9467583b2267",
   "metadata": {},
   "source": [
    "The central limit theorem doesn't just apply to the binomial distribution. It applies to any idependent and identically distributed random numbers from any distribution! `rng.random()` produces random numbers uniformly distributed $\\in [0, 1]$. So let's see whether they become Gaussian when we sum them together.\n",
    "\n",
    "### Write a function to sum up $n$ uniformly distributed random numbers.\n",
    "\n",
    "It should have three parameters:\n",
    "- `rng`, a random number generator\n",
    "- `n`, the amount of numbers to sum up\n",
    "- `num_realizations`, the amount of times you repeat this process\n",
    "\n",
    "It should return:\n",
    "- `outcome`, a 1-dimensional numpy array containing the results for summing $n$ random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5a49f-6b97-49de-8f98-19763b28a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_summed_uni(rng, n, num_realizations):\n",
    "    rands = rng.random(size=(num_realizations, n))\n",
    "    \n",
    "    \"\"\"\n",
    "    Use np.sum and sum the matrix of random numbers over the columns.\n",
    "    Save this result to a variable called outcomes.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    return outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6423004-2312-4469-9a30-bda046912e23",
   "metadata": {},
   "source": [
    "### See how many uniform random numbers you need to sum for things to appear Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456a618-3276-4d17-b618-420330fd0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.array([1, 2, 5, 10, 20, 50])\n",
    "num_realizations = 10000\n",
    "\n",
    "summed_uni_rands = []\n",
    "for n in ns:\n",
    "    summed_uni_rands.append(my_summed_uni(rng, n, num_realizations))\n",
    "    \n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "for ax, rands, n in zip(np.ravel(axes), summed_uni_rands, ns):\n",
    "    bins = np.linspace(np.min(rands), np.max(rands), 30)\n",
    "    ax.hist(rands, bins=bins, density=True, rwidth=0.9, label='uni rands')\n",
    "    ax.plot(bins, sp.norm.pdf(bins, np.mean(rands), np.std(rands)), linewidth=2, label='Gaussian fit')\n",
    "    ax.set_title('summed ' + str(n) + ' rands')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('PMF')\n",
    "    ax.legend()\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b6925-56d8-491a-b8b5-2fd0c5b2632d",
   "metadata": {},
   "source": [
    "### Repeat the same plots as above but instead use a logarithmic scale on the y-axis to inspect the tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a4607-9a4f-4474-aa0a-b831bfd008e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "for ax, rands, n in zip(np.ravel(axes), summed_uni_rands, ns):\n",
    "    bins = np.linspace(np.min(rands), np.max(rands), 30)\n",
    "    ax.hist(rands, bins=bins, density=True, rwidth=0.9, label='uni rands')\n",
    "    ax.plot(bins, sp.norm.pdf(bins, np.mean(rands), np.std(rands)), linewidth=2, label='Gaussian fit')\n",
    "    ax.set_title('summed ' + str(n) + ' rands')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('PMF')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biophys2022",
   "language": "python",
   "name": "biophys2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
